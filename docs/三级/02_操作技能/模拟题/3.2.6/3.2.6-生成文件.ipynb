{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d399ce85-719b-4915-afca-670065a6108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNXæ¨¡å‹å·²ç”Ÿæˆ: animal_classifier.onnx\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnx.helper as helper\n",
    "import numpy as np\n",
    "from onnx import numpy_helper\n",
    "\n",
    "def create_simple_animal_classifier():\n",
    "    \"\"\"åˆ›å»ºä¸€ä¸ªç®€å•çš„åŠ¨ç‰©åˆ†ç±»ONNXæ¨¡å‹\"\"\"\n",
    "    \n",
    "    # æ¨¡å‹è¾“å…¥ï¼š1x3x224x224 (batch, channels, height, width)\n",
    "    input_tensor = helper.make_tensor_value_info('input', onnx.TensorProto.FLOAT, [1, 3, 224, 224])\n",
    "    \n",
    "    # æ¨¡å‹è¾“å‡ºï¼š1x10 (10ä¸ªåŠ¨ç‰©ç±»åˆ«)\n",
    "    output_tensor = helper.make_tensor_value_info('output', onnx.TensorProto.FLOAT, [1, 10])\n",
    "    \n",
    "    # åˆ›å»ºä¸€äº›ç®€å•çš„æ“ä½œèŠ‚ç‚¹ï¼ˆæ¨¡æ‹Ÿä¸€ä¸ªåˆ†ç±»å™¨ï¼‰\n",
    "    nodes = [\n",
    "        # å…¨å±€å¹³å‡æ± åŒ–\n",
    "        helper.make_node(\n",
    "            'GlobalAveragePool',\n",
    "            inputs=['input'],\n",
    "            outputs=['pool_output'],\n",
    "            name='global_pool'\n",
    "        ),\n",
    "        \n",
    "        # å…¨è¿æ¥å±‚ï¼ˆæ¨¡æ‹Ÿåˆ†ç±»å™¨ï¼‰\n",
    "        helper.make_node(\n",
    "            'Gemm',\n",
    "            inputs=['pool_output', 'fc_weight', 'fc_bias'],\n",
    "            outputs=['output'],\n",
    "            name='fc_layer'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # åˆ›å»ºæƒé‡å’Œåç½®ï¼ˆéšæœºåˆå§‹åŒ–ï¼‰\n",
    "    fc_weight = numpy_helper.from_array(\n",
    "        np.random.randn(10, 3).astype(np.float32), \n",
    "        name='fc_weight'\n",
    "    )\n",
    "    \n",
    "    fc_bias = numpy_helper.from_array(\n",
    "        np.random.randn(10).astype(np.float32), \n",
    "        name='fc_bias'\n",
    "    )\n",
    "    \n",
    "    # åˆ›å»ºå›¾\n",
    "    graph = helper.make_graph(\n",
    "        nodes=nodes,\n",
    "        name='animal_classifier',\n",
    "        inputs=[input_tensor],\n",
    "        outputs=[output_tensor],\n",
    "        initializer=[fc_weight, fc_bias]\n",
    "    )\n",
    "    \n",
    "    # åˆ›å»ºæ¨¡å‹\n",
    "    model = helper.make_model(\n",
    "        graph,\n",
    "        producer_name='animal-classifier',\n",
    "        opset_imports=[helper.make_opsetid(\"\", 12)]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ç”Ÿæˆå¹¶ä¿å­˜æ¨¡å‹\n",
    "model = create_simple_animal_classifier()\n",
    "onnx.save(model, 'animal_classifier.onnx')\n",
    "print(\"ONNXæ¨¡å‹å·²ç”Ÿæˆ: animal_classifier.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "300ac11b-90e1-4a33-83ad-4d86c63a613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç±»åˆ«æ ‡ç­¾æ–‡ä»¶å·²ç”Ÿæˆ: animal_labels.txt\n",
      "åŒ…å«çš„åŠ¨ç‰©ç±»åˆ«:\n",
      "0: éæ´²è±¡\n",
      "1: äºšæ´²è±¡\n",
      "2: ç‹®å­\n",
      "3: è€è™\n",
      "4: é•¿é¢ˆé¹¿\n",
      "5: æ–‘é©¬\n",
      "6: å¤§ç†ŠçŒ«\n",
      "7: åŒ—æç†Š\n",
      "8: çŒè±¹\n",
      "9: çŠ€ç‰›\n"
     ]
    }
   ],
   "source": [
    "# ç”ŸæˆåŠ¨ç‰©ç±»åˆ«æ ‡ç­¾æ–‡ä»¶\n",
    "animal_labels = [\n",
    "    \"éæ´²è±¡\", \"äºšæ´²è±¡\", \"ç‹®å­\", \"è€è™\", \"é•¿é¢ˆé¹¿\",\n",
    "    \"æ–‘é©¬\", \"å¤§ç†ŠçŒ«\", \"åŒ—æç†Š\", \"çŒè±¹\", \"çŠ€ç‰›\"\n",
    "]\n",
    "\n",
    "with open('animal_labels.txt', 'w', encoding='utf-8') as f:\n",
    "    for label in animal_labels:\n",
    "        f.write(label + '\\n')\n",
    "\n",
    "print(\"ç±»åˆ«æ ‡ç­¾æ–‡ä»¶å·²ç”Ÿæˆ: animal_labels.txt\")\n",
    "print(\"åŒ…å«çš„åŠ¨ç‰©ç±»åˆ«:\")\n",
    "for i, animal in enumerate(animal_labels):\n",
    "    print(f\"{i}: {animal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7c3dc7e-f30d-4b26-ad40-4f62ff74880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•å›¾ç‰‡å·²ç”Ÿæˆ: test_animal.jpg (æ¨¡æ‹ŸåŠ¨ç‰©: lion)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "\n",
    "def create_test_animal_image():\n",
    "    \"\"\"åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„åŠ¨ç‰©æµ‹è¯•å›¾ç‰‡\"\"\"\n",
    "    # åˆ›å»ºä¸€ä¸ª224x224çš„å›¾ç‰‡\n",
    "    img = Image.new('RGB', (224, 224), color='lightblue')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # éšæœºé€‰æ‹©ä¸€ä¸ªåŠ¨ç‰©ç±»å‹æ¥ç»˜åˆ¶ç®€å•çš„å½¢çŠ¶\n",
    "    animal_type = random.choice(['elephant', 'lion', 'giraffe', 'zebra'])\n",
    "    \n",
    "    if animal_type == 'elephant':\n",
    "        # ç»˜åˆ¶å¤§è±¡çš„ç®€å•è½®å»“\n",
    "        draw.ellipse([50, 80, 170, 180], fill='gray', outline='black')  # èº«ä½“\n",
    "        draw.ellipse([30, 100, 70, 140], fill='gray', outline='black')  # å¤´éƒ¨\n",
    "        draw.ellipse([20, 110, 40, 120], fill='gray', outline='black')  # è€³æœµ\n",
    "        draw.ellipse([60, 110, 80, 120], fill='gray', outline='black')  # è€³æœµ\n",
    "        draw.line([40, 140, 20, 160], fill='black', width=3)  # é¼»å­\n",
    "        \n",
    "    elif animal_type == 'lion':\n",
    "        # ç»˜åˆ¶ç‹®å­çš„ç®€å•è½®å»“\n",
    "        draw.ellipse([80, 80, 160, 160], fill='goldenrod', outline='black')  # èº«ä½“\n",
    "        draw.ellipse([70, 70, 170, 120], fill='darkgoldenrod', outline='black')  # é¬ƒæ¯›\n",
    "        draw.ellipse([90, 90, 110, 110], fill='black')  # çœ¼ç›\n",
    "        draw.ellipse([130, 90, 150, 110], fill='black')  # çœ¼ç›\n",
    "        \n",
    "    elif animal_type == 'giraffe':\n",
    "        # ç»˜åˆ¶é•¿é¢ˆé¹¿çš„ç®€å•è½®å»“\n",
    "        draw.rectangle([100, 120, 120, 180], fill='yellow', outline='black')  # èº«ä½“\n",
    "        draw.rectangle([95, 80, 105, 120], fill='yellow', outline='black')  # è„–å­\n",
    "        draw.ellipse([90, 70, 110, 90], fill='yellow', outline='black')  # å¤´éƒ¨\n",
    "        draw.ellipse([95, 75, 100, 80], fill='black')  # çœ¼ç›\n",
    "        \n",
    "    elif animal_type == 'zebra':\n",
    "        # ç»˜åˆ¶æ–‘é©¬çš„ç®€å•è½®å»“\n",
    "        draw.ellipse([80, 100, 160, 180], fill='white', outline='black')  # èº«ä½“\n",
    "        # æ·»åŠ æ¡çº¹\n",
    "        for i in range(85, 155, 10):\n",
    "            draw.rectangle([i, 100, i+5, 180], fill='black')\n",
    "    \n",
    "    # æ·»åŠ ä¸€äº›èƒŒæ™¯å…ƒç´ \n",
    "    draw.rectangle([10, 190, 214, 200], fill='green')  # è‰åœ°\n",
    "    \n",
    "    return img, animal_type\n",
    "\n",
    "# ç”Ÿæˆæµ‹è¯•å›¾ç‰‡\n",
    "test_image, animal_type = create_test_animal_image()\n",
    "test_image.save('test_animal.jpg')\n",
    "print(f\"æµ‹è¯•å›¾ç‰‡å·²ç”Ÿæˆ: test_animal.jpg (æ¨¡æ‹ŸåŠ¨ç‰©: {animal_type})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95cd8636-73c2-4dbd-b758-7c1fcc61b3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶ ===\n",
      "âœ— æ–‡ä»¶éªŒè¯å¤±è´¥: [ONNXRuntimeError] : 1 : FAIL : Load model from animal_classifier.onnx failed:Node (fc_layer) Op (Gemm) [ShapeInferenceError] First input does not have rank 2\n"
     ]
    }
   ],
   "source": [
    "def verify_generated_files():\n",
    "    \"\"\"éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶æ˜¯å¦å¯ç”¨\"\"\"\n",
    "    print(\"\\n=== éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶ ===\")\n",
    "    \n",
    "    try:\n",
    "        # éªŒè¯ONNXæ¨¡å‹\n",
    "        import onnxruntime as ort\n",
    "        session = ort.InferenceSession('animal_classifier.onnx')\n",
    "        print(\"âœ“ ONNXæ¨¡å‹åŠ è½½æˆåŠŸ\")\n",
    "        print(f\"  è¾“å…¥: {session.get_inputs()[0].name}\")\n",
    "        print(f\"  è¾“å‡º: {session.get_outputs()[0].name}\")\n",
    "        \n",
    "        # éªŒè¯æ ‡ç­¾æ–‡ä»¶\n",
    "        with open('animal_labels.txt', 'r', encoding='utf-8') as f:\n",
    "            labels = [line.strip() for line in f.readlines()]\n",
    "        print(f\"âœ“ æ ‡ç­¾æ–‡ä»¶åŠ è½½æˆåŠŸï¼Œå…±{len(labels)}ä¸ªç±»åˆ«\")\n",
    "        \n",
    "        # éªŒè¯å›¾ç‰‡æ–‡ä»¶\n",
    "        from PIL import Image\n",
    "        image = Image.open('test_animal.jpg')\n",
    "        print(f\"âœ“ æµ‹è¯•å›¾ç‰‡åŠ è½½æˆåŠŸï¼Œå°ºå¯¸: {image.size}\")\n",
    "        \n",
    "        print(\"\\næ‰€æœ‰æ–‡ä»¶éªŒè¯é€šè¿‡ï¼å¯ä»¥å¼€å§‹åšé¢˜äº†ã€‚\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— æ–‡ä»¶éªŒè¯å¤±è´¥: {e}\")\n",
    "\n",
    "# è¿è¡ŒéªŒè¯\n",
    "verify_generated_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bb739ee-3b7b-41a7-a1dd-f5171daa5f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹ç”ŸæˆONNXæ¨¡å‹æ¨ç†é¢˜ç›®æ–‡ä»¶...\n",
      "1. ç”ŸæˆONNXæ¨¡å‹...\n",
      "âœ“ ONNXæ¨¡å‹ç”ŸæˆæˆåŠŸ\n",
      "2. ç”Ÿæˆç±»åˆ«æ ‡ç­¾æ–‡ä»¶...\n",
      "âœ“ ç±»åˆ«æ ‡ç­¾æ–‡ä»¶ç”ŸæˆæˆåŠŸ\n",
      "3. ç”Ÿæˆæµ‹è¯•å›¾ç‰‡...\n",
      "âœ“ æµ‹è¯•å›¾ç‰‡ç”ŸæˆæˆåŠŸ\n",
      "\n",
      "=== æ–‡ä»¶ç”Ÿæˆå®Œæˆ ===\n",
      "ç”Ÿæˆçš„æ–‡ä»¶:\n",
      "1. animal_classifier.onnx - ONNXæ¨¡å‹æ–‡ä»¶\n",
      "2. animal_labels.txt - åŠ¨ç‰©ç±»åˆ«æ ‡ç­¾\n",
      "3. test_animal.jpg - æµ‹è¯•å›¾ç‰‡\n",
      "\n",
      "åŠ¨ç‰©ç±»åˆ«åˆ—è¡¨:\n",
      "   0: éæ´²è±¡\n",
      "   1: äºšæ´²è±¡\n",
      "   2: ç‹®å­\n",
      "   3: è€è™\n",
      "   4: é•¿é¢ˆé¹¿\n",
      "   5: æ–‘é©¬\n",
      "   6: å¤§ç†ŠçŒ«\n",
      "   7: åŒ—æç†Š\n",
      "   8: çŒè±¹\n",
      "   9: çŠ€ç‰›\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnx.helper as helper\n",
    "import numpy as np\n",
    "from onnx import numpy_helper\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def generate_onnx_model_files():\n",
    "    \"\"\"ç”ŸæˆONNXæ¨¡å‹æ¨ç†é¢˜ç›®æ‰€éœ€çš„æ‰€æœ‰æ–‡ä»¶\"\"\"\n",
    "    \n",
    "    print(\"å¼€å§‹ç”ŸæˆONNXæ¨¡å‹æ¨ç†é¢˜ç›®æ–‡ä»¶...\")\n",
    "    \n",
    "    # 1. ç”ŸæˆONNXæ¨¡å‹ - ä¿®å¤ç‰ˆæœ¬\n",
    "    print(\"1. ç”ŸæˆONNXæ¨¡å‹...\")\n",
    "    def create_simple_animal_classifier():\n",
    "        # æ¨¡å‹è¾“å…¥ï¼š1x3x224x224 (batch, channels, height, width)\n",
    "        input_tensor = helper.make_tensor_value_info('input', onnx.TensorProto.FLOAT, [1, 3, 224, 224])\n",
    "        \n",
    "        # æ¨¡å‹è¾“å‡ºï¼š1x10 (10ä¸ªåŠ¨ç‰©ç±»åˆ«)\n",
    "        output_tensor = helper.make_tensor_value_info('output', onnx.TensorProto.FLOAT, [1, 10])\n",
    "        \n",
    "        # åˆ›å»ºæ›´ç®€å•çš„æ¨¡å‹ç»“æ„\n",
    "        nodes = [\n",
    "            # å…¨å±€å¹³å‡æ± åŒ– - è¾“å‡ºå½¢çŠ¶: [1, 3, 1, 1]\n",
    "            helper.make_node(\n",
    "                'GlobalAveragePool',\n",
    "                inputs=['input'],\n",
    "                outputs=['pool_output'],\n",
    "                name='global_pool'\n",
    "            ),\n",
    "            \n",
    "            # é‡å¡‘ä¸º [1, 3] ä»¥åŒ¹é…å…¨è¿æ¥å±‚\n",
    "            helper.make_node(\n",
    "                'Reshape',\n",
    "                inputs=['pool_output', 'reshape_shape'],\n",
    "                outputs=['reshape_output'],\n",
    "                name='reshape'\n",
    "            ),\n",
    "            \n",
    "            # å…¨è¿æ¥å±‚\n",
    "            helper.make_node(\n",
    "                'Gemm',\n",
    "                inputs=['reshape_output', 'fc_weight', 'fc_bias'],\n",
    "                outputs=['output'],\n",
    "                name='fc_layer'\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # åˆ›å»ºå¸¸é‡å¼ é‡\n",
    "        reshape_shape = numpy_helper.from_array(\n",
    "            np.array([1, 3], dtype=np.int64), \n",
    "            name='reshape_shape'\n",
    "        )\n",
    "        \n",
    "        # åˆ›å»ºæƒé‡å’Œåç½®ï¼ˆéšæœºåˆå§‹åŒ–ï¼‰\n",
    "        fc_weight = numpy_helper.from_array(\n",
    "            np.random.randn(10, 3).astype(np.float32), \n",
    "            name='fc_weight'\n",
    "        )\n",
    "        \n",
    "        fc_bias = numpy_helper.from_array(\n",
    "            np.random.randn(10).astype(np.float32), \n",
    "            name='fc_bias'\n",
    "        )\n",
    "        \n",
    "        # åˆ›å»ºå›¾\n",
    "        graph = helper.make_graph(\n",
    "            nodes=nodes,\n",
    "            name='animal_classifier',\n",
    "            inputs=[input_tensor],\n",
    "            outputs=[output_tensor],\n",
    "            initializer=[reshape_shape, fc_weight, fc_bias]\n",
    "        )\n",
    "        \n",
    "        # åˆ›å»ºæ¨¡å‹\n",
    "        model = helper.make_model(\n",
    "            graph,\n",
    "            producer_name='animal-classifier',\n",
    "            opset_imports=[helper.make_opsetid(\"\", 13)]\n",
    "        )\n",
    "        \n",
    "        # æ£€æŸ¥æ¨¡å‹\n",
    "        onnx.checker.check_model(model)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    try:\n",
    "        model = create_simple_animal_classifier()\n",
    "        onnx.save(model, 'animal_classifier.onnx')\n",
    "        print(\"âœ“ ONNXæ¨¡å‹ç”ŸæˆæˆåŠŸ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— ONNXæ¨¡å‹ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 2. ç”Ÿæˆç±»åˆ«æ ‡ç­¾\n",
    "    print(\"2. ç”Ÿæˆç±»åˆ«æ ‡ç­¾æ–‡ä»¶...\")\n",
    "    animal_labels = [\n",
    "        \"éæ´²è±¡\", \"äºšæ´²è±¡\", \"ç‹®å­\", \"è€è™\", \"é•¿é¢ˆé¹¿\",\n",
    "        \"æ–‘é©¬\", \"å¤§ç†ŠçŒ«\", \"åŒ—æç†Š\", \"çŒè±¹\", \"çŠ€ç‰›\"\n",
    "    ]\n",
    "    \n",
    "    with open('animal_labels.txt', 'w', encoding='utf-8') as f:\n",
    "        for label in animal_labels:\n",
    "            f.write(label + '\\n')\n",
    "    print(\"âœ“ ç±»åˆ«æ ‡ç­¾æ–‡ä»¶ç”ŸæˆæˆåŠŸ\")\n",
    "    \n",
    "    # 3. ç”Ÿæˆæµ‹è¯•å›¾ç‰‡\n",
    "    print(\"3. ç”Ÿæˆæµ‹è¯•å›¾ç‰‡...\")\n",
    "    def create_test_image():\n",
    "        # åˆ›å»ºä¸€ä¸ª224x224çš„å½©è‰²å›¾ç‰‡\n",
    "        img = Image.new('RGB', (224, 224), color=(173, 216, 230))  # æµ…è“è‰²èƒŒæ™¯\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        # ç»˜åˆ¶ä¸€ä¸ªç®€å•çš„åŠ¨ç‰©è½®å»“ï¼ˆå¤§è±¡ï¼‰\n",
    "        # èº«ä½“\n",
    "        draw.ellipse([60, 100, 164, 180], fill=(128, 128, 128), outline=(0, 0, 0), width=2)\n",
    "        # å¤´éƒ¨\n",
    "        draw.ellipse([40, 80, 100, 120], fill=(128, 128, 128), outline=(0, 0, 0), width=2)\n",
    "        # è€³æœµ\n",
    "        draw.ellipse([30, 85, 50, 105], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        draw.ellipse([90, 85, 110, 105], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        # é¼»å­\n",
    "        draw.rectangle([45, 110, 55, 130], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        # è…¿\n",
    "        draw.rectangle([70, 170, 80, 190], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        draw.rectangle([90, 170, 100, 190], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        draw.rectangle([124, 170, 134, 190], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        draw.rectangle([144, 170, 154, 190], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        # è‰åœ°\n",
    "        draw.rectangle([0, 190, 224, 200], fill=(34, 139, 34), outline=(0, 0, 0), width=1)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    try:\n",
    "        test_image = create_test_image()\n",
    "        test_image.save('test_animal.jpg', quality=95)\n",
    "        print(\"âœ“ æµ‹è¯•å›¾ç‰‡ç”ŸæˆæˆåŠŸ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— æµ‹è¯•å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n=== æ–‡ä»¶ç”Ÿæˆå®Œæˆ ===\")\n",
    "    print(\"ç”Ÿæˆçš„æ–‡ä»¶:\")\n",
    "    print(\"1. animal_classifier.onnx - ONNXæ¨¡å‹æ–‡ä»¶\")\n",
    "    print(\"2. animal_labels.txt - åŠ¨ç‰©ç±»åˆ«æ ‡ç­¾\")\n",
    "    print(\"3. test_animal.jpg - æµ‹è¯•å›¾ç‰‡\")\n",
    "    \n",
    "    print(\"\\nåŠ¨ç‰©ç±»åˆ«åˆ—è¡¨:\")\n",
    "    for i, animal in enumerate(animal_labels):\n",
    "        print(f\"   {i}: {animal}\")\n",
    "\n",
    "# æ‰§è¡Œç”Ÿæˆ\n",
    "if __name__ == \"__main__\":\n",
    "    generate_onnx_model_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee228b30-0e9d-44d1-a7d5-593e8db7798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== æµ‹è¯•å®Œæ•´æ¨ç†æµç¨‹ ===\n",
      "âœ— æ¨ç†æµç¨‹æµ‹è¯•å¤±è´¥: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type. Actual: (tensor(double)) , expected: (tensor(float))\n"
     ]
    }
   ],
   "source": [
    "def test_complete_inference():\n",
    "    \"\"\"æµ‹è¯•å®Œæ•´çš„æ¨ç†æµç¨‹\"\"\"\n",
    "    print(\"\\n=== æµ‹è¯•å®Œæ•´æ¨ç†æµç¨‹ ===\")\n",
    "    \n",
    "    try:\n",
    "        import onnxruntime as ort\n",
    "        import numpy as np\n",
    "        from PIL import Image\n",
    "        import scipy.special\n",
    "        \n",
    "        # 1. åŠ è½½æ¨¡å‹\n",
    "        session = ort.InferenceSession('animal_classifier.onnx')\n",
    "        input_name = session.get_inputs()[0].name\n",
    "        output_name = session.get_outputs()[0].name\n",
    "        \n",
    "        # 2. åŠ è½½æ ‡ç­¾\n",
    "        with open('animal_labels.txt', 'r', encoding='utf-8') as f:\n",
    "            labels = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        # 3. é¢„å¤„ç†å‡½æ•°\n",
    "        def preprocess_image(image_path, target_size=(224, 224)):\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = image.resize(target_size)\n",
    "            image_array = np.array(image).astype(np.float32)\n",
    "            image_array = image_array / 255.0\n",
    "            mean = [0.485, 0.456, 0.406]\n",
    "            std = [0.229, 0.224, 0.225]\n",
    "            image_array = (image_array - mean) / std\n",
    "            image_array = np.transpose(image_array, (2, 0, 1))\n",
    "            image_array = np.expand_dims(image_array, axis=0)\n",
    "            return image_array\n",
    "        \n",
    "        # 4. é¢„å¤„ç†å›¾åƒ\n",
    "        processed_image = preprocess_image('test_animal.jpg')\n",
    "        \n",
    "        # 5. æ‰§è¡Œæ¨ç†\n",
    "        outputs = session.run([output_name], {input_name: processed_image})\n",
    "        \n",
    "        # 6. åå¤„ç†\n",
    "        probabilities = scipy.special.softmax(outputs[0], axis=1)\n",
    "        predicted_class_idx = np.argmax(probabilities[0])\n",
    "        confidence = probabilities[0][predicted_class_idx]\n",
    "        predicted_label = labels[predicted_class_idx]\n",
    "        \n",
    "        print(f\"é¢„æµ‹ç»“æœ: {predicted_label}\")\n",
    "        print(f\"ç½®ä¿¡åº¦: {confidence:.4f}\")\n",
    "        \n",
    "        # 7. Top-3 ç»“æœ\n",
    "        top3_indices = np.argsort(probabilities[0])[-3:][::-1]\n",
    "        top3_confidences = probabilities[0][top3_indices]\n",
    "        \n",
    "        print(\"\\nTop-3 é¢„æµ‹ç»“æœ:\")\n",
    "        for i, (idx, conf) in enumerate(zip(top3_indices, top3_confidences)):\n",
    "            print(f\"{i+1}. {labels[idx]} - {conf:.4f}\")\n",
    "            \n",
    "        print(\"\\nğŸ‰ å®Œæ•´æ¨ç†æµç¨‹æµ‹è¯•æˆåŠŸï¼\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— æ¨ç†æµç¨‹æµ‹è¯•å¤±è´¥: {e}\")\n",
    "\n",
    "# è¿è¡Œå®Œæ•´æµ‹è¯•\n",
    "test_complete_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6acd8ed2-e10d-4e6a-9310-02fa04c2338e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹ç”ŸæˆONNXæ¨¡å‹æ¨ç†é¢˜ç›®æ–‡ä»¶...\n",
      "1. ç”ŸæˆONNXæ¨¡å‹...\n",
      "âœ“ ONNXæ¨¡å‹ç”ŸæˆæˆåŠŸ\n",
      "2. ç”Ÿæˆç±»åˆ«æ ‡ç­¾æ–‡ä»¶...\n",
      "âœ“ ç±»åˆ«æ ‡ç­¾æ–‡ä»¶ç”ŸæˆæˆåŠŸ\n",
      "3. ç”Ÿæˆæµ‹è¯•å›¾ç‰‡...\n",
      "âœ“ æµ‹è¯•å›¾ç‰‡ç”ŸæˆæˆåŠŸ\n",
      "\n",
      "=== æ–‡ä»¶ç”Ÿæˆå®Œæˆ ===\n",
      "ç”Ÿæˆçš„æ–‡ä»¶:\n",
      "1. animal_classifier.onnx - ONNXæ¨¡å‹æ–‡ä»¶\n",
      "2. animal_labels.txt - åŠ¨ç‰©ç±»åˆ«æ ‡ç­¾\n",
      "3. test_animal.jpg - æµ‹è¯•å›¾ç‰‡\n",
      "\n",
      "åŠ¨ç‰©ç±»åˆ«åˆ—è¡¨:\n",
      "   0: éæ´²è±¡\n",
      "   1: äºšæ´²è±¡\n",
      "   2: ç‹®å­\n",
      "   3: è€è™\n",
      "   4: é•¿é¢ˆé¹¿\n",
      "   5: æ–‘é©¬\n",
      "   6: å¤§ç†ŠçŒ«\n",
      "   7: åŒ—æç†Š\n",
      "   8: çŒè±¹\n",
      "   9: çŠ€ç‰›\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnx.helper as helper\n",
    "import numpy as np\n",
    "from onnx import numpy_helper\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def generate_onnx_model_files():\n",
    "    \"\"\"ç”ŸæˆONNXæ¨¡å‹æ¨ç†é¢˜ç›®æ‰€éœ€çš„æ‰€æœ‰æ–‡ä»¶\"\"\"\n",
    "    \n",
    "    print(\"å¼€å§‹ç”ŸæˆONNXæ¨¡å‹æ¨ç†é¢˜ç›®æ–‡ä»¶...\")\n",
    "    \n",
    "    # 1. ç”ŸæˆONNXæ¨¡å‹ - ä¿®å¤æ•°æ®ç±»å‹é—®é¢˜\n",
    "    print(\"1. ç”ŸæˆONNXæ¨¡å‹...\")\n",
    "    def create_simple_animal_classifier():\n",
    "        # æ¨¡å‹è¾“å…¥ï¼š1x3x224x224 (batch, channels, height, width)\n",
    "        input_tensor = helper.make_tensor_value_info('input', onnx.TensorProto.FLOAT, [1, 3, 224, 224])\n",
    "        \n",
    "        # æ¨¡å‹è¾“å‡ºï¼š1x10 (10ä¸ªåŠ¨ç‰©ç±»åˆ«)\n",
    "        output_tensor = helper.make_tensor_value_info('output', onnx.TensorProto.FLOAT, [1, 10])\n",
    "        \n",
    "        # åˆ›å»ºæ›´ç®€å•çš„æ¨¡å‹ç»“æ„ - é¿å…å¤æ‚çš„æ“ä½œ\n",
    "        nodes = [\n",
    "            # ä½¿ç”¨å·ç§¯å±‚æ›¿ä»£å…¨è¿æ¥å±‚ï¼Œé¿å…å½¢çŠ¶é—®é¢˜\n",
    "            helper.make_node(\n",
    "                'Conv',\n",
    "                inputs=['input', 'conv_weight', 'conv_bias'],\n",
    "                outputs=['conv_output'],\n",
    "                name='conv_layer',\n",
    "                kernel_shape=[1, 1],  # 1x1å·ç§¯ï¼Œç›¸å½“äºå…¨è¿æ¥\n",
    "                strides=[1, 1],\n",
    "                pads=[0, 0, 0, 0]\n",
    "            ),\n",
    "            \n",
    "            # å…¨å±€å¹³å‡æ± åŒ–\n",
    "            helper.make_node(\n",
    "                'GlobalAveragePool',\n",
    "                inputs=['conv_output'],\n",
    "                outputs=['pool_output'],\n",
    "                name='global_pool'\n",
    "            ),\n",
    "            \n",
    "            # é‡å¡‘ä¸ºæ­£ç¡®çš„è¾“å‡ºå½¢çŠ¶\n",
    "            helper.make_node(\n",
    "                'Reshape',\n",
    "                inputs=['pool_output', 'reshape_shape'],\n",
    "                outputs=['output'],\n",
    "                name='reshape_output'\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # åˆ›å»ºæƒé‡ - ç¡®ä¿æ˜¯float32ç±»å‹\n",
    "        conv_weight = numpy_helper.from_array(\n",
    "            np.random.randn(10, 3, 1, 1).astype(np.float32),  # 10ä¸ªè¾“å‡ºé€šé“ï¼Œ3ä¸ªè¾“å…¥é€šé“ï¼Œ1x1å·ç§¯æ ¸\n",
    "            name='conv_weight'\n",
    "        )\n",
    "        \n",
    "        conv_bias = numpy_helper.from_array(\n",
    "            np.random.randn(10).astype(np.float32),\n",
    "            name='conv_bias'\n",
    "        )\n",
    "        \n",
    "        # é‡å¡‘å½¢çŠ¶\n",
    "        reshape_shape = numpy_helper.from_array(\n",
    "            np.array([1, 10], dtype=np.int64),\n",
    "            name='reshape_shape'\n",
    "        )\n",
    "        \n",
    "        # åˆ›å»ºå›¾\n",
    "        graph = helper.make_graph(\n",
    "            nodes=nodes,\n",
    "            name='animal_classifier',\n",
    "            inputs=[input_tensor],\n",
    "            outputs=[output_tensor],\n",
    "            initializer=[conv_weight, conv_bias, reshape_shape]\n",
    "        )\n",
    "        \n",
    "        # åˆ›å»ºæ¨¡å‹\n",
    "        model = helper.make_model(\n",
    "            graph,\n",
    "            producer_name='animal-classifier',\n",
    "            opset_imports=[helper.make_opsetid(\"\", 13)]\n",
    "        )\n",
    "        \n",
    "        # æ£€æŸ¥æ¨¡å‹\n",
    "        onnx.checker.check_model(model)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    try:\n",
    "        model = create_simple_animal_classifier()\n",
    "        onnx.save(model, 'animal_classifier.onnx')\n",
    "        print(\"âœ“ ONNXæ¨¡å‹ç”ŸæˆæˆåŠŸ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— ONNXæ¨¡å‹ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 2. ç”Ÿæˆç±»åˆ«æ ‡ç­¾\n",
    "    print(\"2. ç”Ÿæˆç±»åˆ«æ ‡ç­¾æ–‡ä»¶...\")\n",
    "    animal_labels = [\n",
    "        \"éæ´²è±¡\", \"äºšæ´²è±¡\", \"ç‹®å­\", \"è€è™\", \"é•¿é¢ˆé¹¿\",\n",
    "        \"æ–‘é©¬\", \"å¤§ç†ŠçŒ«\", \"åŒ—æç†Š\", \"çŒè±¹\", \"çŠ€ç‰›\"\n",
    "    ]\n",
    "    \n",
    "    with open('animal_labels.txt', 'w', encoding='utf-8') as f:\n",
    "        for label in animal_labels:\n",
    "            f.write(label + '\\n')\n",
    "    print(\"âœ“ ç±»åˆ«æ ‡ç­¾æ–‡ä»¶ç”ŸæˆæˆåŠŸ\")\n",
    "    \n",
    "    # 3. ç”Ÿæˆæµ‹è¯•å›¾ç‰‡\n",
    "    print(\"3. ç”Ÿæˆæµ‹è¯•å›¾ç‰‡...\")\n",
    "    def create_test_image():\n",
    "        # åˆ›å»ºä¸€ä¸ª224x224çš„å½©è‰²å›¾ç‰‡\n",
    "        img = Image.new('RGB', (224, 224), color=(173, 216, 230))  # æµ…è“è‰²èƒŒæ™¯\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        # ç»˜åˆ¶ä¸€ä¸ªç®€å•çš„åŠ¨ç‰©è½®å»“ï¼ˆå¤§è±¡ï¼‰\n",
    "        # èº«ä½“\n",
    "        draw.ellipse([60, 100, 164, 180], fill=(128, 128, 128), outline=(0, 0, 0), width=2)\n",
    "        # å¤´éƒ¨\n",
    "        draw.ellipse([40, 80, 100, 120], fill=(128, 128, 128), outline=(0, 0, 0), width=2)\n",
    "        # è€³æœµ\n",
    "        draw.ellipse([30, 85, 50, 105], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        draw.ellipse([90, 85, 110, 105], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        # é¼»å­\n",
    "        draw.rectangle([45, 110, 55, 130], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        # è…¿\n",
    "        draw.rectangle([70, 170, 80, 190], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        draw.rectangle([90, 170, 100, 190], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        draw.rectangle([124, 170, 134, 190], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        draw.rectangle([144, 170, 154, 190], fill=(128, 128, 128), outline=(0, 0, 0), width=1)\n",
    "        # è‰åœ°\n",
    "        draw.rectangle([0, 190, 224, 200], fill=(34, 139, 34), outline=(0, 0, 0), width=1)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    try:\n",
    "        test_image = create_test_image()\n",
    "        test_image.save('test_animal.jpg', quality=95)\n",
    "        print(\"âœ“ æµ‹è¯•å›¾ç‰‡ç”ŸæˆæˆåŠŸ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— æµ‹è¯•å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n=== æ–‡ä»¶ç”Ÿæˆå®Œæˆ ===\")\n",
    "    print(\"ç”Ÿæˆçš„æ–‡ä»¶:\")\n",
    "    print(\"1. animal_classifier.onnx - ONNXæ¨¡å‹æ–‡ä»¶\")\n",
    "    print(\"2. animal_labels.txt - åŠ¨ç‰©ç±»åˆ«æ ‡ç­¾\")\n",
    "    print(\"3. test_animal.jpg - æµ‹è¯•å›¾ç‰‡\")\n",
    "    \n",
    "    print(\"\\nåŠ¨ç‰©ç±»åˆ«åˆ—è¡¨:\")\n",
    "    for i, animal in enumerate(animal_labels):\n",
    "        print(f\"   {i}: {animal}\")\n",
    "\n",
    "# æ‰§è¡Œç”Ÿæˆ\n",
    "if __name__ == \"__main__\":\n",
    "    generate_onnx_model_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2250daf-0254-4792-9595-1b712f1ba20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== æµ‹è¯•å®Œæ•´æ¨ç†æµç¨‹ ===\n",
      "é¢„å¤„ç†å›¾åƒæ•°æ®ç±»å‹: float32\n",
      "é¢„å¤„ç†å›¾åƒå½¢çŠ¶: (1, 3, 224, 224)\n",
      "é¢„æµ‹ç»“æœ: è€è™\n",
      "ç½®ä¿¡åº¦: 0.4131\n",
      "\n",
      "Top-3 é¢„æµ‹ç»“æœ:\n",
      "1. è€è™ - 0.4131\n",
      "2. éæ´²è±¡ - 0.2929\n",
      "3. é•¿é¢ˆé¹¿ - 0.1967\n",
      "\n",
      "ğŸ‰ å®Œæ•´æ¨ç†æµç¨‹æµ‹è¯•æˆåŠŸï¼\n"
     ]
    }
   ],
   "source": [
    "def test_complete_inference():\n",
    "    \"\"\"æµ‹è¯•å®Œæ•´çš„æ¨ç†æµç¨‹ - ä¿®å¤æ•°æ®ç±»å‹é—®é¢˜\"\"\"\n",
    "    print(\"\\n=== æµ‹è¯•å®Œæ•´æ¨ç†æµç¨‹ ===\")\n",
    "    \n",
    "    try:\n",
    "        import onnxruntime as ort\n",
    "        import numpy as np\n",
    "        from PIL import Image\n",
    "        import scipy.special\n",
    "        \n",
    "        # 1. åŠ è½½æ¨¡å‹\n",
    "        session = ort.InferenceSession('animal_classifier.onnx')\n",
    "        input_name = session.get_inputs()[0].name\n",
    "        output_name = session.get_outputs()[0].name\n",
    "        \n",
    "        # 2. åŠ è½½æ ‡ç­¾\n",
    "        with open('animal_labels.txt', 'r', encoding='utf-8') as f:\n",
    "            labels = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        # 3. é¢„å¤„ç†å‡½æ•° - ç¡®ä¿è¾“å‡ºæ˜¯float32\n",
    "        def preprocess_image(image_path, target_size=(224, 224)):\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = image.resize(target_size)\n",
    "            image_array = np.array(image).astype(np.float32)  # ç¡®ä¿æ˜¯float32\n",
    "            image_array = image_array / 255.0\n",
    "            mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)  # ç¡®ä¿meanæ˜¯float32\n",
    "            std = np.array([0.229, 0.224, 0.225], dtype=np.float32)   # ç¡®ä¿stdæ˜¯float32\n",
    "            image_array = (image_array - mean) / std\n",
    "            image_array = np.transpose(image_array, (2, 0, 1))\n",
    "            image_array = np.expand_dims(image_array, axis=0)\n",
    "            return image_array\n",
    "        \n",
    "        # 4. é¢„å¤„ç†å›¾åƒ\n",
    "        processed_image = preprocess_image('test_animal.jpg')\n",
    "        print(f\"é¢„å¤„ç†å›¾åƒæ•°æ®ç±»å‹: {processed_image.dtype}\")\n",
    "        print(f\"é¢„å¤„ç†å›¾åƒå½¢çŠ¶: {processed_image.shape}\")\n",
    "        \n",
    "        # 5. æ‰§è¡Œæ¨ç†\n",
    "        outputs = session.run([output_name], {input_name: processed_image})\n",
    "        \n",
    "        # 6. åå¤„ç†\n",
    "        probabilities = scipy.special.softmax(outputs[0], axis=1)\n",
    "        predicted_class_idx = np.argmax(probabilities[0])\n",
    "        confidence = probabilities[0][predicted_class_idx]\n",
    "        predicted_label = labels[predicted_class_idx]\n",
    "        \n",
    "        print(f\"é¢„æµ‹ç»“æœ: {predicted_label}\")\n",
    "        print(f\"ç½®ä¿¡åº¦: {confidence:.4f}\")\n",
    "        \n",
    "        # 7. Top-3 ç»“æœ\n",
    "        top3_indices = np.argsort(probabilities[0])[-3:][::-1]\n",
    "        top3_confidences = probabilities[0][top3_indices]\n",
    "        \n",
    "        print(\"\\nTop-3 é¢„æµ‹ç»“æœ:\")\n",
    "        for i, (idx, conf) in enumerate(zip(top3_indices, top3_confidences)):\n",
    "            print(f\"{i+1}. {labels[idx]} - {conf:.4f}\")\n",
    "            \n",
    "        print(\"\\nğŸ‰ å®Œæ•´æ¨ç†æµç¨‹æµ‹è¯•æˆåŠŸï¼\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— æ¨ç†æµç¨‹æµ‹è¯•å¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# è¿è¡Œå®Œæ•´æµ‹è¯•\n",
    "test_complete_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd1acd-e5d7-4634-b13a-35639f310829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
